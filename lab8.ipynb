{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-10T11:48:49.241648Z",
     "iopub.status.busy": "2025-05-10T11:48:49.240838Z",
     "iopub.status.idle": "2025-05-10T11:48:52.684131Z",
     "shell.execute_reply": "2025-05-10T11:48:52.683122Z",
     "shell.execute_reply.started": "2025-05-10T11:48:49.241622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q ultralytics --upgrade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:01:06.160275Z",
     "iopub.status.busy": "2025-05-10T13:01:06.160002Z",
     "iopub.status.idle": "2025-05-10T13:01:06.167087Z",
     "shell.execute_reply": "2025-05-10T13:01:06.166577Z",
     "shell.execute_reply.started": "2025-05-10T13:01:06.160254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, random, pathlib, zipfile, shutil\n",
    "import pandas as pd, numpy as np, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassConfusionMatrix\n",
    ")\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "IMG_SIZE    = 224\n",
    "BATCH_SIZE  = 32\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS_BL   = 10\n",
    "EPOCHS_IMP  = 20\n",
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:01:15.663890Z",
     "iopub.status.busy": "2025-05-10T13:01:15.663631Z",
     "iopub.status.idle": "2025-05-10T13:01:15.702121Z",
     "shell.execute_reply": "2025-05-10T13:01:15.701519Z",
     "shell.execute_reply.started": "2025-05-10T13:01:15.663873Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Cataracta                921\n",
      "Angiopathia                  790\n",
      "Myopia                  500\n",
      "Mis Glaucoma    495\n",
      "Amblyopia              461\n",
      "Polycoria             436\n",
      "Keratitis                  420\n",
      "Blepharitis          411\n",
      "Aniridia          318\n",
      "Name: count, dtype: int64\n",
      "Found 9 classes: ['Amblyopia', 'Blepharitis', 'Keratitis', 'Angiopathia', 'Mis Glaucoma', 'Myopia', 'Cataracta', 'Aniridia', 'Polycoria']\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = pathlib.Path(\"/kaggle/input/eye-diseases/eye-diseases-main/EyeDiseases\")\n",
    "all_images = []\n",
    "for class_idx, class_name in enumerate(sorted(p.name for p in DATA_DIR.iterdir())):\n",
    "    for img_path in (DATA_DIR / class_name).glob(\"*\"):\n",
    "        all_images.append((str(img_path), class_idx, class_name))\n",
    "df = pd.DataFrame(all_images, columns=[\"path\",\"label\",\"class\"])\n",
    "print(df['class'].value_counts())\n",
    "NUM_CLASSES = df.label.nunique()\n",
    "class_names = sorted(df[\"class\"].unique())\n",
    "print(f\"Found {NUM_CLASSES} classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:01:30.711980Z",
     "iopub.status.busy": "2025-05-10T13:01:30.711380Z",
     "iopub.status.idle": "2025-05-10T13:01:30.723373Z",
     "shell.execute_reply": "2025-05-10T13:01:30.722432Z",
     "shell.execute_reply.started": "2025-05-10T13:01:30.711955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3326, val: 713, test: 713\n"
     ]
    }
   ],
   "source": [
    "train_df, tmp_df = train_test_split(\n",
    "    df, test_size=0.30, random_state=SEED, stratify=df[\"label\"]\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    tmp_df, test_size=0.50, random_state=SEED, stratify=tmp_df[\"label\"]\n",
    ")\n",
    "print(f\"train: {len(train_df)}, val: {len(val_df)}, test: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:01:38.578669Z",
     "iopub.status.busy": "2025-05-10T13:01:38.578334Z",
     "iopub.status.idle": "2025-05-10T13:01:38.588682Z",
     "shell.execute_reply": "2025-05-10T13:01:38.587897Z",
     "shell.execute_reply.started": "2025-05-10T13:01:38.578643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, df, tfm):\n",
    "        self.df  = df.reset_index(drop=True)\n",
    "        self.tfm = tfm\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.df.loc[i,\"path\"]).convert(\"RGB\")\n",
    "        x = self.tfm(img)\n",
    "        y = self.df.loc[i,\"label\"]\n",
    "        return x, y\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    WasteDataset(train_df, train_tfms),\n",
    "    batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    WasteDataset(val_df, val_tfms),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    WasteDataset(test_df, val_tfms),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T11:49:01.420245Z",
     "iopub.status.busy": "2025-05-10T11:49:01.419590Z",
     "iopub.status.idle": "2025-05-10T11:49:01.431204Z",
     "shell.execute_reply": "2025-05-10T11:49:01.430364Z",
     "shell.execute_reply.started": "2025-05-10T11:49:01.420215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"acc\"       : MulticlassAccuracy(NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\"  : MulticlassF1Score(NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\" : MulticlassF1Score(NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"top3\"      : MulticlassAccuracy(NUM_CLASSES, top_k=3).to(device),\n",
    "    \"cm\"        : MulticlassConfusionMatrix(NUM_CLASSES).to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:04:31.610393Z",
     "iopub.status.busy": "2025-05-10T13:04:31.610063Z",
     "iopub.status.idle": "2025-05-10T13:04:52.490235Z",
     "shell.execute_reply": "2025-05-10T13:04:52.489604Z",
     "shell.execute_reply.started": "2025-05-10T13:04:31.610370Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Папки eye-diseases_split/train, val, test созданы\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"eye-diseases_split\")\n",
    "if OUT_DIR.exists():\n",
    "    shutil.rmtree(OUT_DIR)\n",
    "\n",
    "for split, df_split in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "    for _, row in df_split.iterrows():\n",
    "        cls = row[\"class\"]\n",
    "        src = Path(row[\"path\"])\n",
    "        dst_dir = OUT_DIR / split / cls\n",
    "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(src, dst_dir / src.name)\n",
    "\n",
    "print(\"✓ Папки eye-diseases_split/train, val, test созданы\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:10:09.290172Z",
     "iopub.status.busy": "2025-05-10T13:10:09.289868Z",
     "iopub.status.idle": "2025-05-10T13:10:09.296030Z",
     "shell.execute_reply": "2025-05-10T13:10:09.295411Z",
     "shell.execute_reply.started": "2025-05-10T13:10:09.290149Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: /kaggle/working/eye-diseases_split/train\n",
      "val:   /kaggle/working/eye-diseases_split/val\n",
      "test:  /kaggle/working/eye-diseases_split/test\n",
      "\n",
      "nc: 9\n",
      "names: ['Amblyopia', 'Blepharitis', 'Keratitis', 'Angiopathia', 'Mis Glaucoma', 'Myopia', 'Cataracta', 'Aniridia', 'Polycoria']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"eye-diseases_split\").resolve()\n",
    "\n",
    "yaml_content = f\"\"\"\n",
    "train: {ROOT}/train\n",
    "val:   {ROOT}/val\n",
    "test:  {ROOT}/test\n",
    "\n",
    "nc: {NUM_CLASSES}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "with open(\"eye-diseases.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content.strip())\n",
    "print(open(\"eye-diseases.yaml\").read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:12:19.665524Z",
     "iopub.status.busy": "2025-05-10T13:12:19.665271Z",
     "iopub.status.idle": "2025-05-10T13:12:20.685757Z",
     "shell.execute_reply": "2025-05-10T13:12:20.685115Z",
     "shell.execute_reply.started": "2025-05-10T13:12:19.665507Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Скопировали `eye-diseases_split` → `/kaggle/working/datasets/eye-diseases_split`\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "src = \"eye-diseases_split\"\n",
    "dst = \"/kaggle/working/datasets/eye-diseases_split\"\n",
    "\n",
    "if os.path.exists(dst):\n",
    "    shutil.rmtree(dst)\n",
    "\n",
    "shutil.copytree(src, dst)\n",
    "print(f\"✓ Скопировали `{src}` → `{dst}`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:33:14.690828Z",
     "iopub.status.busy": "2025-05-10T13:33:14.690565Z",
     "iopub.status.idle": "2025-05-10T13:33:14.696412Z",
     "shell.execute_reply": "2025-05-10T13:33:14.695735Z",
     "shell.execute_reply.started": "2025-05-10T13:33:14.690811Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# корень ваших данных — eye-diseases_split (ищется в datasets_dir)\n",
      "path: eye-diseases_split\n",
      "\n",
      "train: train\n",
      "val:   val\n",
      "test:  test\n",
      "\n",
      "nc: 9\n",
      "names: ['Amblyopia', 'Blepharitis', 'Keratitis', 'Angiopathia', 'Mis Glaucoma', 'Myopia', 'Cataracta', 'Aniridia', 'Polycoria']\n"
     ]
    }
   ],
   "source": [
    "yaml = f\"\"\"\n",
    "path: eye-diseases_split\n",
    "\n",
    "train: train\n",
    "val:   val\n",
    "test:  test\n",
    "\n",
    "nc: {NUM_CLASSES}\n",
    "names: {class_names}\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(\"eye-diseases.yaml\",\"w\") as f:\n",
    "    f.write(yaml)\n",
    "\n",
    "print(open(\"eye-diseases.yaml\").read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:37:34.304913Z",
     "iopub.status.busy": "2025-05-10T13:37:34.304601Z",
     "iopub.status.idle": "2025-05-10T13:40:40.610666Z",
     "shell.execute_reply": "2025-05-10T13:40:40.609714Z",
     "shell.execute_reply.started": "2025-05-10T13:37:34.304891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/eye-diseases_split, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=baseline_yolov8n-cls3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/classify/baseline_yolov8n-cls3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/eye-diseases_split/train... found 3326 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/eye-diseases_split/val... found 713 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/eye-diseases_split/test... found 713 images in 9 classes ✅ \n",
      "Overriding model.yaml nc=1000 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    341769  ultralytics.nn.modules.head.Classify         [256, 9]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,449,817 parameters, 1,449,817 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2181.4±656.7 MB/s, size: 136.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/eye-diseases_split/train... 3326 images, 0 corrupt: 100%|██████████| 3326/3326 [00:01<00:00, 3025.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/eye-diseases_split/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 559.5±456.8 MB/s, size: 155.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/eye-diseases_split/val... 713 images, 0 corrupt: 100%|██████████| 713/713 [00:00<00:00, 2936.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/eye-diseases_split/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/baseline_yolov8n-cls3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      2.64G      1.787         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.26it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.648       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      2.64G     0.9221         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.79      0.996\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/10      2.64G     0.6733         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.827      0.996\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/10      2.64G     0.5245         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.996\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       5/10      2.64G     0.4479         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.75it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.864      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       6/10      2.64G     0.3759         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.857          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/10      2.64G     0.3211         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.877      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       8/10      2.64G     0.2822         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.882          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       9/10      2.64G     0.2591         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.90it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.889          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      10/10      2.64G     0.2377         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.896          1\n",
      "\n",
      "10 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from runs/classify/baseline_yolov8n-cls3/weights/last.pt, 3.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs/classify/baseline_yolov8n-cls3/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating runs/classify/baseline_yolov8n-cls3/weights/best.pt...\n",
      "Ultralytics 8.3.130 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,446,409 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/eye-diseases_split/train... found 3326 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/realwaste_split/val... found 713 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/eye-diseases_split/test... found 713 images in 9 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.01it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.896          1\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/baseline_yolov8n-cls3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7b7de5660810>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.948106586933136\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.896213173866272, 'metrics/accuracy_top5': 1.0, 'fitness': 0.948106586933136}\n",
       "save_dir: PosixPath('runs/classify/baseline_yolov8n-cls3')\n",
       "speed: {'preprocess': 0.06615461851043615, 'inference': 0.2234480659135596, 'loss': 0.0002156535746537209, 'postprocess': 0.00033953015120333614}\n",
       "task: 'classify'\n",
       "top1: 0.896213173866272\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = str(Path(\"eye-diseases_split\").resolve())\n",
    "model_clf = YOLO('yolov8n-cls.pt', task='classify')\n",
    "model_clf.train(\n",
    "    data=ROOT,       \n",
    "    epochs=EPOCHS_BL,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=NUM_WORKERS,\n",
    "    device=device.type,\n",
    "    name='baseline_yolov8n-cls'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:48:06.374360Z",
     "iopub.status.busy": "2025-05-10T13:48:06.374015Z",
     "iopub.status.idle": "2025-05-10T13:48:10.085999Z",
     "shell.execute_reply": "2025-05-10T13:48:10.085019Z",
     "shell.execute_reply.started": "2025-05-10T13:48:06.374328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2370434a96504e61bc14aa3c26605fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferencing on test:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (micro)     : 0.3745\n",
      "F1-score (macro)     : 0.3208\n",
      "F1-score (weighted)  : 0.3594\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassConfusionMatrix\n",
    ")\n",
    "\n",
    "# 1) Определяем ваши метрики\n",
    "metrics = {\n",
    "    \"acc\"       : MulticlassAccuracy(NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\"  : MulticlassF1Score(NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\" : MulticlassF1Score(NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"top3\"      : MulticlassAccuracy(NUM_CLASSES, top_k=3).to(device),\n",
    "    \"cm\"        : MulticlassConfusionMatrix(NUM_CLASSES).to(device),\n",
    "}\n",
    "\n",
    "model = model_clf.model\n",
    "model.to(device).eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in tqdm(test_dl, desc=\"Inferencing on test\"):\n",
    "        xb = xb.to(device); yb = yb.to(device)\n",
    "        out = model(xb)\n",
    "        logits = out[1] if isinstance(out, (tuple, list)) else out\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(yb)\n",
    "\n",
    "y_pred = torch.cat(all_preds)\n",
    "y_true = torch.cat(all_labels)\n",
    "\n",
    "acc       = metrics[\"acc\"](y_pred, y_true)\n",
    "f1_macro  = metrics[\"f1_macro\"](y_pred, y_true)\n",
    "f1_weight = metrics[\"f1_weight\"](y_pred, y_true)\n",
    "cm        = metrics[\"cm\"](y_pred, y_true)\n",
    "\n",
    "print(f\"Accuracy (micro)     : {acc:.4f}\")\n",
    "print(f\"F1-score (macro)     : {f1_macro:.4f}\")\n",
    "print(f\"F1-score (weighted)  : {f1_weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:56:16.518984Z",
     "iopub.status.busy": "2025-05-10T13:56:16.518532Z",
     "iopub.status.idle": "2025-05-10T13:56:16.543096Z",
     "shell.execute_reply": "2025-05-10T13:56:16.542216Z",
     "shell.execute_reply.started": "2025-05-10T13:56:16.518949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts:\n",
      " label\n",
      "0    323\n",
      "1    288\n",
      "2    294\n",
      "3    553\n",
      "4    346\n",
      "5    350\n",
      "6    645\n",
      "7    222\n",
      "8    305\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "counts = train_df['label'].value_counts().sort_index()\n",
    "print(\"Train class counts:\\n\", counts)\n",
    "\n",
    "class_weights = 1.0 / counts.values\n",
    "sample_weights = train_df['label'].map(lambda x: class_weights[x]).values\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    WasteDataset(train_df, train_tfms),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:59:34.546915Z",
     "iopub.status.busy": "2025-05-10T13:59:34.546616Z",
     "iopub.status.idle": "2025-05-10T13:59:34.552500Z",
     "shell.execute_reply": "2025-05-10T13:59:34.551703Z",
     "shell.execute_reply.started": "2025-05-10T13:59:34.546894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = df.label.nunique()\n",
    "class_names = sorted(df['class'].unique())\n",
    "ROOT = str(Path(\"eye-diseases_split\").resolve())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:59:47.707333Z",
     "iopub.status.busy": "2025-05-10T13:59:47.707011Z",
     "iopub.status.idle": "2025-05-10T13:59:47.715426Z",
     "shell.execute_reply": "2025-05-10T13:59:47.714602Z",
     "shell.execute_reply.started": "2025-05-10T13:59:47.707312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "counts = train_df['label'].value_counts().sort_index()\n",
    "class_weights = 1.0 / counts.values\n",
    "sample_weights = train_df['label'].map(lambda x: class_weights[x]).values\n",
    "\n",
    "sampler = WeightedRandomSampler(sample_weights,\n",
    "                                num_samples=len(sample_weights),\n",
    "                                replacement=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:59:58.796136Z",
     "iopub.status.busy": "2025-05-10T13:59:58.795526Z",
     "iopub.status.idle": "2025-05-10T13:59:58.802153Z",
     "shell.execute_reply": "2025-05-10T13:59:58.801305Z",
     "shell.execute_reply.started": "2025-05-10T13:59:58.796112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7,1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, \n",
    "                           saturation=0.2, hue=0.1),\n",
    "    transforms.RandomErasing(p=0.4, scale=(0.02,0.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:00:08.769089Z",
     "iopub.status.busy": "2025-05-10T14:00:08.768809Z",
     "iopub.status.idle": "2025-05-10T14:00:08.777256Z",
     "shell.execute_reply": "2025-05-10T14:00:08.776586Z",
     "shell.execute_reply.started": "2025-05-10T14:00:08.769069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, df, tfm):\n",
    "        self.df  = df.reset_index(drop=True)\n",
    "        self.tfm = tfm\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.df.loc[i,'path']).convert('RGB')\n",
    "        return self.tfm(img), self.df.loc[i,'label']\n",
    "\n",
    "train_ds = WasteDataset(train_df, train_tfms)\n",
    "val_ds   = WasteDataset(val_df,   val_tfms)\n",
    "test_ds  = WasteDataset(test_df,  val_tfms)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                      sampler=sampler,\n",
    "                      num_workers=NUM_WORKERS,\n",
    "                      pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE,\n",
    "                      shuffle=False,\n",
    "                      num_workers=NUM_WORKERS,\n",
    "                      pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE,\n",
    "                      shuffle=False,\n",
    "                      num_workers=NUM_WORKERS,\n",
    "                      pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:00:20.746272Z",
     "iopub.status.busy": "2025-05-10T14:00:20.745993Z",
     "iopub.status.idle": "2025-05-10T14:07:48.772815Z",
     "shell.execute_reply": "2025-05-10T14:07:48.772052Z",
     "shell.execute_reply.started": "2025-05-10T14:00:20.746251Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/eye-diseases_split, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=improved_yolov8m-cls, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/classify/improved_yolov8m-cls, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/eye-diseases_split/train... found 3326 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/eye-diseases_split/val... found 713 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/eye-diseases_split/test... found 713 images in 9 classes ✅ \n",
      "Overriding model.yaml nc=1000 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
      "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
      "  9                  -1  1    997129  ultralytics.nn.modules.head.Classify         [768, 9]                      \n",
      "YOLOv8m-cls summary: 80 layers, 15,783,865 parameters, 15,783,865 gradients, 41.9 GFLOPs\n",
      "Transferred 228/230 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2670.8±651.4 MB/s, size: 136.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/eye-diseases_split/train... 3326 images, 0 corrupt: 100%|██████████| 3326/3326 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 761.4±678.2 MB/s, size: 155.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/eye-diseases_split/val... 713 images, 0 corrupt: 100%|██████████| 713/713 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/improved_yolov8m-cls\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      1.42G      1.714         30        224: 100%|██████████| 104/104 [00:17<00:00,  5.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.746      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      1.62G      0.654         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.846          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      1.62G     0.4912         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.805      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      1.62G     0.4171         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.856      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      1.62G     0.3397         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.878      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      1.62G     0.2504         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.884      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      1.62G      0.188         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.896      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      1.62G     0.1493         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.886      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      1.62G     0.1259         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.903      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      1.62G    0.09691         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.907      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      1.62G     0.1056         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      1.62G     0.1003         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.92      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      1.62G     0.0776         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.913      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      1.62G    0.06124         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.921      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      1.62G    0.05914         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.924      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      1.62G    0.05141         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.926      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      1.62G    0.05222         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.924      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      1.62G    0.03922         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      1.62G    0.04496         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      1.62G    0.03214         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.106 hours.\n",
      "Optimizer stripped from runs/classify/improved_yolov8m-cls/weights/last.pt, 31.7MB\n",
      "Optimizer stripped from runs/classify/improved_yolov8m-cls/weights/best.pt, 31.7MB\n",
      "\n",
      "Validating runs/classify/improved_yolov8m-cls/weights/best.pt...\n",
      "Ultralytics 8.3.130 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLOv8m-cls summary (fused): 42 layers, 15,774,185 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/eye-diseases_split/train... found 3326 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/eye-diseases_split/val... found 713 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/eye-diseases_split/test... found 713 images in 9 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.02it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.934      0.999\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/improved_yolov8m-cls\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7b7de5363450>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9663394391536713\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9340813755989075, 'metrics/accuracy_top5': 0.9985975027084351, 'fitness': 0.9663394391536713}\n",
       "save_dir: PosixPath('runs/classify/improved_yolov8m-cls')\n",
       "speed: {'preprocess': 0.07118607152741256, 'inference': 0.7027562875152473, 'loss': 0.0002141514746341619, 'postprocess': 0.000487870966791447}\n",
       "task: 'classify'\n",
       "top1: 0.9340813755989075\n",
       "top5: 0.9985975027084351"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imp = YOLO('yolov8m-cls.pt', task='classify')\n",
    "model_imp.train(\n",
    "    data=ROOT,\n",
    "    epochs=EPOCHS_IMP,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=NUM_WORKERS,\n",
    "    device=device.type,\n",
    "    name='improved_yolov8m-cls',\n",
    "    lr0=0.01,\n",
    "    lrf=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:11:35.875321Z",
     "iopub.status.busy": "2025-05-10T14:11:35.875028Z",
     "iopub.status.idle": "2025-05-10T14:11:59.768727Z",
     "shell.execute_reply": "2025-05-10T14:11:59.767869Z",
     "shell.execute_reply.started": "2025-05-10T14:11:35.875300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dce217095e4ac4b0d45254476f7fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferencing:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.5610, f1_macro=0.5512, f1_weight=0.5609\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassConfusionMatrix\n",
    ")\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "# инициализируем\n",
    "k = min(3, NUM_CLASSES)\n",
    "metrics = {\n",
    "    \"acc\"       : MulticlassAccuracy(NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\"  : MulticlassF1Score(NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\" : MulticlassF1Score(NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"cm\"        : MulticlassConfusionMatrix(NUM_CLASSES).to(device),\n",
    "}\n",
    "\n",
    "# инференс на model_imp\n",
    "mdl = model_imp.model.to(device).eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in tqdm(test_dl, desc=\"Inferencing\"):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = mdl(xb)\n",
    "        logits = out[1] if isinstance(out,(tuple,list)) else out\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.append(preds); all_labels.append(yb)\n",
    "\n",
    "y_pred = torch.cat(all_preds)\n",
    "y_true = torch.cat(all_labels)\n",
    "\n",
    "# считаем\n",
    "acc       = metrics[\"acc\"](y_pred, y_true)\n",
    "f1m       = metrics[\"f1_macro\"](y_pred, y_true)\n",
    "f1w       = metrics[\"f1_weight\"](y_pred, y_true)\n",
    "cm        = metrics[\"cm\"](y_pred, y_true)\n",
    "\n",
    "print(f\"acc={acc:.4f}, f1_macro={f1m:.4f}, f1_weight={f1w:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к трансформерам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:15:54.348968Z",
     "iopub.status.busy": "2025-05-10T14:15:54.348343Z",
     "iopub.status.idle": "2025-05-10T14:15:54.365497Z",
     "shell.execute_reply": "2025-05-10T14:15:54.364572Z",
     "shell.execute_reply.started": "2025-05-10T14:15:54.348940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "counts = train_df['label'].value_counts().sort_index()\n",
    "class_weights   = 1.0 / counts.values\n",
    "sample_weights  = train_df['label'].map(lambda x: class_weights[x]).values\n",
    "sampler         = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7,1.0)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, df, tfm):\n",
    "        self.df  = df.reset_index(drop=True); self.tfm = tfm\n",
    "    def __len__(self):    return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.df.loc[i,'path']).convert('RGB')\n",
    "        return self.tfm(img), self.df.loc[i,'label']\n",
    "\n",
    "train_dl = DataLoader(WasteDataset(train_df, train_tfms),\n",
    "                      batch_size=BATCH_SIZE, sampler=sampler,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dl   = DataLoader(WasteDataset(val_df,   val_tfms),\n",
    "                      batch_size=BATCH_SIZE, shuffle=False,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dl  = DataLoader(WasteDataset(test_df,  val_tfms),\n",
    "                      batch_size=BATCH_SIZE, shuffle=False,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:16:13.553574Z",
     "iopub.status.busy": "2025-05-10T14:16:13.552843Z",
     "iopub.status.idle": "2025-05-10T14:19:25.828878Z",
     "shell.execute_reply": "2025-05-10T14:19:25.827866Z",
     "shell.execute_reply.started": "2025-05-10T14:16:13.553521Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.52M/5.52M [00:00<00:00, 73.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/eye-diseases_split, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=baseline_yolo11n-cls, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/classify/baseline_yolo11n-cls, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/eye-diseases_split/train... found 3326 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/eye-diseases_split/val... found 713 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/eye-diseases_split/test... found 713 images in 9 classes ✅ \n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    341769  ultralytics.nn.modules.head.Classify         [256, 9]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,542,633 parameters, 1,542,633 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2588.3±825.2 MB/s, size: 136.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/eye-diseases_split/train... 3326 images, 0 corrupt: 100%|██████████| 3326/3326 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 689.5±526.4 MB/s, size: 155.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/eye-diseases_split/val... 713 images, 0 corrupt: 100%|██████████| 713/713 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/baseline_yolo11n-cls\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.859G      1.548         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.762      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.863G     0.7446         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.863G      0.587         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.816      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.863G     0.5268         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.833      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.863G     0.4425         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.34it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.86          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.863G     0.3461         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.87          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.863G     0.2977         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.43it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.896      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.863G     0.2281         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.896      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.863G     0.2035         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.907      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.863G      0.181         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.905      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from runs/classify/baseline_yolo11n-cls/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from runs/classify/baseline_yolo11n-cls/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating runs/classify/baseline_yolo11n-cls/weights/best.pt...\n",
      "Ultralytics 8.3.130 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,537,553 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/eye-diseases_split/train... found 3326 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/eye-diseases_split/val... found 713 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/eye-diseases_split/test... found 713 images in 9 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.45it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.907      0.997\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/baseline_yolo11n-cls\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7b7eb4249350>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.952314168214798\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9074333906173706, 'metrics/accuracy_top5': 0.9971949458122253, 'fitness': 0.952314168214798}\n",
       "save_dir: PosixPath('runs/classify/baseline_yolo11n-cls')\n",
       "speed: {'preprocess': 0.07345088359274556, 'inference': 0.23884099298462122, 'loss': 0.0002172945378040294, 'postprocess': 0.00033080225226617593}\n",
       "task: 'classify'\n",
       "top1: 0.9074333906173706\n",
       "top5: 0.9971949458122253"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bl = YOLO('yolo11n-cls.pt', task='classify')\n",
    "model_bl.train(\n",
    "    data=ROOT,         \n",
    "    epochs=EPOCHS_BL,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=NUM_WORKERS,\n",
    "    device=device.type,\n",
    "    name='baseline_yolo11n-cls',\n",
    "    lr0=0.01,          \n",
    "    lrf=0.1            \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:20:05.540640Z",
     "iopub.status.busy": "2025-05-10T14:20:05.540295Z",
     "iopub.status.idle": "2025-05-10T14:26:36.521600Z",
     "shell.execute_reply": "2025-05-10T14:26:36.520532Z",
     "shell.execute_reply.started": "2025-05-10T14:20:05.540611Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-cls.pt to 'yolo11m-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22.4M/22.4M [00:00<00:00, 176MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/eye-diseases_split, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11m-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=improved_yolo11m-cls, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/classify/improved_yolo11m-cls, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/eye-diseases_split/train... found 3326 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/eye-diseases_split/val... found 713 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/eye-diseases_split/test... found 713 images in 9 classes ✅ \n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 10                  -1  1    669449  ultralytics.nn.modules.head.Classify         [512, 9]                      \n",
      "YOLO11m-cls summary: 106 layers, 10,364,745 parameters, 10,364,745 gradients, 39.6 GFLOPs\n",
      "Transferred 294/296 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2791.9±845.0 MB/s, size: 136.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/eye-diseases_split/train... 3326 images, 0 corrupt: 100%|██████████| 3326/3326 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 726.8±717.2 MB/s, size: 155.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/eye-diseases_split/val... 713 images, 0 corrupt: 100%|██████████| 713/713 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 49 weight(decay=0.0), 50 weight(decay=0.0005), 50 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/improved_yolo11m-cls\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      1.83G      1.374         30        224: 100%|██████████| 104/104 [00:17<00:00,  5.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.822      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      2.18G     0.6167         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.83      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      2.18G     0.6611         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.788      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      2.18G     0.7026         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.40it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.809      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      2.18G     0.6069         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.823      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      2.18G      0.494         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.868      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      2.18G     0.3908         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.865      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      2.18G     0.3309         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.875          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      2.18G     0.3085         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.875          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      2.18G     0.2205         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.878      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      2.18G     0.2295         30        224: 100%|██████████| 104/104 [00:17<00:00,  6.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.896      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      2.18G     0.2296         30        224: 100%|██████████| 104/104 [00:15<00:00,  6.51it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.885      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      2.18G     0.1939         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.891      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      2.18G     0.1529         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.886      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      2.18G     0.1372         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.903      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      2.18G     0.1115         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.899      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      2.18G    0.08714         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.917      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      2.18G    0.08839         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:01<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.919      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      2.18G    0.07762         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.43it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.919      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      2.18G    0.07218         30        224: 100%|██████████| 104/104 [00:16<00:00,  6.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.917      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.106 hours.\n",
      "Optimizer stripped from runs/classify/improved_yolo11m-cls/weights/last.pt, 20.9MB\n",
      "Optimizer stripped from runs/classify/improved_yolo11m-cls/weights/best.pt, 20.9MB\n",
      "\n",
      "Validating runs/classify/improved_yolo11m-cls/weights/best.pt...\n",
      "Ultralytics 8.3.130 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11m-cls summary (fused): 57 layers, 10,353,161 parameters, 0 gradients, 39.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/eye-diseases_split/train... found 3326 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/eye-diseases_split/val... found 713 images in 9 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/eye-diseases_split/test... found 713 images in 9 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 12/12 [00:02<00:00,  5.85it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.919      0.999\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/improved_yolo11m-cls\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7b7eea305d50>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9586255252361298\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9186535477638245, 'metrics/accuracy_top5': 0.9985975027084351, 'fitness': 0.9586255252361298}\n",
       "save_dir: PosixPath('runs/classify/improved_yolo11m-cls')\n",
       "speed: {'preprocess': 0.07123184992913334, 'inference': 0.7085205329575809, 'loss': 0.00025602524849810854, 'postprocess': 0.0004479018253524726}\n",
       "task: 'classify'\n",
       "top1: 0.9186535477638245\n",
       "top5: 0.9985975027084351"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# более крупная трансформерная версия (YOLO11m-cls)\n",
    "model_imp = YOLO('yolo11m-cls.pt', task='classify')\n",
    "model_imp.train(\n",
    "    data=ROOT,\n",
    "    epochs=EPOCHS_IMP,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=NUM_WORKERS,\n",
    "    device=device.type,\n",
    "    name='improved_yolo11m-cls',\n",
    "    lr0=0.01,\n",
    "    lrf=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:27:19.891755Z",
     "iopub.status.busy": "2025-05-10T14:27:19.891417Z",
     "iopub.status.idle": "2025-05-10T14:27:47.590476Z",
     "shell.execute_reply": "2025-05-10T14:27:47.589387Z",
     "shell.execute_reply.started": "2025-05-10T14:27:19.891724Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2ef15d9a114fc8b0ca3281e03e92f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferencing:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5e7e09c2eb46dfb46139022c80bfe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferencing:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline YOLO11n-cls: {'acc': 0.3843, 'f1_macro': 0.3325, 'f1_weight': 0.3507}\n",
      "Improved YOLO11m-cls: {'acc': 0.568, 'f1_macro': 0.5381, 'f1_weight': 0.5534}\n"
     ]
    }
   ],
   "source": [
    "# инициализация torchmetrics\n",
    "k = min(3, NUM_CLASSES)\n",
    "metrics = {\n",
    "    \"acc\"      : MulticlassAccuracy(NUM_CLASSES, average=\"micro\").to(device),\n",
    "    \"f1_macro\" : MulticlassF1Score(NUM_CLASSES, average=\"macro\").to(device),\n",
    "    \"f1_weight\": MulticlassF1Score(NUM_CLASSES, average=\"weighted\").to(device),\n",
    "    \"cm\"       : MulticlassConfusionMatrix(NUM_CLASSES).to(device),\n",
    "}\n",
    "\n",
    "def eval_model(yolo_model, dl):\n",
    "    mdl = yolo_model.model.to(device).eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(dl, desc=\"Inferencing\"):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = mdl(xb)\n",
    "            logits = out[1] if isinstance(out,(tuple,list)) else out\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.append(preds); all_labels.append(yb)\n",
    "    y_pred = torch.cat(all_preds); y_true = torch.cat(all_labels)\n",
    "    return {\n",
    "        'acc':      metrics[\"acc\"](y_pred, y_true).item(),\n",
    "        'f1_macro': metrics[\"f1_macro\"](y_pred, y_true).item(),\n",
    "        'f1_weight':metrics[\"f1_weight\"](y_pred, y_true).item(),\n",
    "        'cm':       metrics[\"cm\"](y_pred, y_true).cpu().numpy()\n",
    "    }\n",
    "\n",
    "# eval baseline\n",
    "res_bl = eval_model(model_bl, test_dl)\n",
    "# eval improved\n",
    "res_imp = eval_model(model_imp, test_dl)\n",
    "\n",
    "# печать\n",
    "print(\"Baseline YOLO11n-cls:\", {k:round(v,4) for k,v in res_bl.items() if k!='cm'})\n",
    "print(\"Improved YOLO11m-cls:\",{k:round(v,4) for k,v in res_imp.items() if k!='cm'})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4324996,
     "sourceId": 7432092,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
